{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ONNX Export Demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference: https://pytorch.org/tutorials//beginner/onnx/export_simple_model_to_onnx_tutorial.html#save-the-onnx-model-in-a-file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a simple linear regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorweaver as torch\n",
    "from tensorweaver.toy_datasets.get_celsius_fahrenheit_dataset import (\n",
    "    get_celsius_fahrenheit_dataset,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset\n",
    "x_array, y_array = get_celsius_fahrenheit_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, loss 4844.748521018383\n",
      "epoch 1000, loss 6.175406086208859\n",
      "epoch 2000, loss 0.8484577318163624\n",
      "epoch 3000, loss 0.8151147321064127\n",
      "epoch 4000, loss 0.814906028068809\n",
      "epoch 5000, loss 0.8149047217263782\n",
      "epoch 6000, loss 0.8149047135495807\n",
      "epoch 7000, loss 0.8149047134984003\n",
      "epoch 8000, loss 0.8149047134980808\n",
      "epoch 9000, loss 0.814904713498079\n"
     ]
    }
   ],
   "source": [
    "# define our model, a simple linear regression model\n",
    "class LinearRegressionModel(torch.nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(LinearRegressionModel, self).__init__()\n",
    "        self.linear = torch.nn.Linear(1, 1)  # One in and one out\n",
    "\n",
    "    def forward(self, x):\n",
    "        y_pred = self.linear(x)\n",
    "        return y_pred\n",
    "\n",
    "\n",
    "# create our model\n",
    "our_model = LinearRegressionModel()\n",
    "\n",
    "# convert the dataset to tensors\n",
    "x = torch.tensor(x_array)  # temperature in celsius\n",
    "y = torch.tensor(y_array)  # temperature in fahrenheit\n",
    "\n",
    "# define our loss function and optimizer\n",
    "criterion = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(our_model.parameters(), lr=0.0015)\n",
    "\n",
    "# train our model\n",
    "loss_path = []\n",
    "\n",
    "for epoch in range(10000):\n",
    "    # Forward pass: Compute predicted y by passing\n",
    "    # x to the model\n",
    "    pred_y = our_model(x)\n",
    "\n",
    "    # Compute and print loss\n",
    "    loss = criterion(pred_y, y)\n",
    "\n",
    "    # Zero gradients, perform a backward pass,\n",
    "    # and update the weights.\n",
    "    optimizer.zero_grad()\n",
    "    loss_path.append(loss.item())\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if epoch % 1000 == 0:\n",
    "        print('epoch {}, loss {}'.format(epoch, loss.item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export our trained model to ONNX format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_inputs = (torch.tensor(((0.0,), (100.0,))),)\n",
    "onnx_program = torch.onnx.export(our_model, example_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "onnx_program.save(\"model.onnx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display our exported ONNX model by using netron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"800\"\n",
       "            src=\"http://localhost:16033\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x13089c510>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pip install -q netron\n",
    "\n",
    "import netron\n",
    "address = netron.serve('model.onnx', verbosity=0)\n",
    "netron.widget(address, height=800)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using onnxruntime to load and run our exported ONNX model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input length: 1\n",
      "Sample input: [array([[  0.],\n",
      "       [100.]])]\n",
      "onnx runtime outputs:  [[ 31.8789119 ]\n",
      " [212.05132774]]\n",
      "expected outputs: 0 celsius -> 32 fahrenheit, 100 celsius -> 212 fahrenheit\n"
     ]
    }
   ],
   "source": [
    "%pip install -q onnxruntime\n",
    "\n",
    "import onnxruntime\n",
    "\n",
    "onnx_inputs = [tensor.numpy() for tensor in example_inputs]\n",
    "print(f\"Sample input: {onnx_inputs}\")\n",
    "\n",
    " # will solve wired errors on some machines: pthread_setaffinity_np\n",
    "session_options = onnxruntime.SessionOptions()\n",
    "session_options.intra_op_num_threads = 1\n",
    "\n",
    "ort_session = onnxruntime.InferenceSession(\n",
    "    \"./model.onnx\",\n",
    "    providers=[\"CPUExecutionProvider\"],\n",
    "    sess_options=session_options\n",
    ")\n",
    "\n",
    "onnxruntime_input = {input_arg.name: input_value for input_arg, input_value in zip(ort_session.get_inputs(), onnx_inputs)}\n",
    "\n",
    "# ONNX Runtime returns a list of outputs\n",
    "onnxruntime_outputs = ort_session.run(None, onnxruntime_input)[0]\n",
    "\n",
    "print(\"onnx runtime outputs: \", onnxruntime_outputs)\n",
    "print(\"expected outputs: 0 celsius -> 32 fahrenheit, 100 celsius -> 212 fahrenheit\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorweaver-l0yEMTWK-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
